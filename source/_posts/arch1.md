---
title: 随机全局优化方法和梯度的结合
---
随机全局优化方法如粒子群优化、遗传算法和布谷鸟搜索等在各种科学和工程优化问题中得到了广泛的应用，其优势在于不需要良好的初始猜测，且能够处理多态且非凸的目标函数而不需要假设其连续性和可微性。但是受限于其严格的随机游走策略，随机全局优化方法需要花费大量的计算和时间去得到一个优化解，收敛速度要远低于基于梯度的算法。

基于这一问题，论文[1]提出在梯度可得时，可以在随机优化算法中结合上梯度，实现在不破坏全局搜索能力的前提下提高优化算法的收敛性。其针对的目标算法是布谷鸟搜索(Cuckoo Search，CS)算法，一种受自然启发的基于群体的随机全局优化方法。与其他优化方法相比， CS采用了一种有效的随机策略Lévy fight，包括频繁的短距离移动和偶尔的长距离跳跃，从而允许CS生成距离当前最佳方案很远的潜在更好的解决方案(即通过长距离跳跃)。这使得CS不太可能陷入局部最优。另外，CS优化算法的控制参数比其他优化算法的控制参数要少，适合的优化问题范围更广。但是CS的Lévy flight搜索策略纯粹是随机的，因此搜索收敛速度相对较低。在寻找最优解的过程中浪费了大量的计算资源，特别是在大规模优化问题中。由此作者提出在梯度容易获取的应用中，可以利用梯度分量改进随机游走的方向，使随机过程带有一定的方向性，加速搜索过程的收敛。然而在随机全局优化算法中加入梯度信息也有可能使得搜索过程过早收敛，破坏算法的全局搜索能力，在算法实现过程中需要设置参数控制基于梯度的随机游走的使用，使算法能够快速地在当前较优方案附近快速找到局部最优点，同时又有机会跳出局部最优，探索更远处的潜在的最优解。最终实验结果表明，改进的基于梯度的CS算法收敛速度快、精度高、全局最优值求解成功率高，在大规模优化问题中具有明显的优越性。

然而对梯度信息的需要一定程度上也限制了该改进算法的应用。对许多优化问题来说，其本质上就是不可微的，这个时候结合梯度的优化算法就无法适用了。而论文[2]中的代理目标函数方法为解决该问题提供了新思路。论文[2]针对的优化问题是加速器上的DNN任务映射，目标是找到一组最优的映射策略使得加速器上DNN任务执行的时延、能耗等最小。但是该优化问题的搜索空间本质上是不平滑和非凸的(具有多个局部最小值)，对映射策略的微小改变会导致整体成本函数的不平滑变化。由此文中提出使用深度神经网络训练一个可微代理函数来逼近原本不可微的优化目标，从而得到近似梯度，后续直接使用梯度下降算法搜索最优映射。然而梯度下降算法的一个问题就是每次都是贪心地选择函数值下降最快的方向行进，容易陷入局部最小值，当其到达局部极小时，更新量为0，算法没有能力跳出局部最小值搜索潜在的更有映射。为了避免陷入局部最小值，论文提出结合“模拟退火”中的方法，在每一步都以一定的概率接受比当前解更差的结果，从而帮助"跳出"局部极小。同时在每步迭代过程中，接受"次优解"的概率随时间的推移而逐渐降低，从而保证算法稳定。

随机全局优化算法全局搜索能力强但收敛速度慢，梯度下降算法收敛速度快但是容易陷入局部最优解，二者适当地结合可以取长补短，带来新的突破。随机全局优化算法结合梯度可以提高收敛速度，而梯度下降算法结合一定随机性可以避免陷入局部最优，这些都为我们解决类似的优化问题拓宽了新思路。

同时可以看到，针对不可微的优化问题，首先通过训练一个深度神经网络来逼近原始函数得到一个可微的代理目标函数并获取梯度信息，同时使用基于梯度的随机全局优化搜索算法来搜索最优解，或将是一个新思路。



### 参考文献： 

[1] She B, Fournier A, Yao M, et al. A self-adaptive and gradient-based cuckoo search algorithm for global optimization[J]. Applied Soft Computing, 2022, 122: 108774.

[2] Hegde K, Tsai P A, Huang S, et al. Mind mappings: enabling efficient algorithm-accelerator mapping space search[C]//Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. 2021: 943-958.